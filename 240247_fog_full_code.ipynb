{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Library Import & Set Random State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('font', family = 'Gulim')\n",
    "mpl.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define CSI Score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSI(y_test, y_pred):\n",
    "    matrix = {\n",
    "        'H11': 0, 'H22': 0, 'H33': 0,\n",
    "        'F12': 0, 'F13': 0, 'F14': 0,\n",
    "        'F21': 0, 'F23': 0, 'F24': 0,\n",
    "        'F31': 0, 'F32': 0, 'F34': 0,\n",
    "        'F41': 0, 'F42': 0, 'F43': 0,\n",
    "        'M14': 0, 'M24': 0, 'M34': 0\n",
    "    }\n",
    "\n",
    "    # 매트릭스 채우기\n",
    "    for true, pred in zip(y_test, y_pred):\n",
    "        if true == pred:\n",
    "            if true == 1:\n",
    "                matrix['H11'] += 1\n",
    "            elif true == 2:\n",
    "                matrix['H22'] += 1\n",
    "            elif true == 3:\n",
    "                matrix['H33'] += 1\n",
    "        else:\n",
    "            if true == 1:\n",
    "                if pred == 2:\n",
    "                    matrix['F12'] += 1\n",
    "                elif pred == 3:\n",
    "                    matrix['F13'] += 1\n",
    "                elif pred == 4:\n",
    "                    matrix['F14'] += 1\n",
    "            elif true == 2:\n",
    "                if pred == 1:\n",
    "                    matrix['F21'] += 1\n",
    "                elif pred == 3:\n",
    "                    matrix['F23'] += 1\n",
    "                elif pred == 4:\n",
    "                    matrix['F24'] += 1\n",
    "            elif true == 3:\n",
    "                if pred == 1:\n",
    "                    matrix['F31'] += 1\n",
    "                elif pred == 2:\n",
    "                    matrix['F32'] += 1\n",
    "                elif pred == 4:\n",
    "                    matrix['F34'] += 1\n",
    "            elif true == 4:\n",
    "                if pred == 1:\n",
    "                    matrix['F41'] += 1\n",
    "                elif pred == 2:\n",
    "                    matrix['F42'] += 1\n",
    "                elif pred == 3:\n",
    "                    matrix['F43'] += 1\n",
    "\n",
    "    # H, F, M 계산\n",
    "    H = matrix['H11'] + matrix['H22'] + matrix['H33']\n",
    "    F = (matrix['F12'] + matrix['F13'] + matrix['F14'] +\n",
    "        matrix['F21'] + matrix['F23'] + matrix['F24'] +\n",
    "        matrix['F31'] + matrix['F32'] + matrix['F34'] +\n",
    "        matrix['F42'] + matrix['F43'])\n",
    "    M = matrix['M14'] + matrix['M24'] + matrix['M34']\n",
    "\n",
    "    # CSI 계산\n",
    "    CSI = H / (H + F + M)\n",
    "    print(f'CSI: {CSI}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Pre-processing & Making Derived Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3133943, 18), (262800, 17))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/fog_train.csv')\n",
    "test = pd.read_csv('data/fog_test.csv')\n",
    "\n",
    "# change column names in train data\n",
    "cols = train.columns[1:].to_list()\n",
    "train = train[cols]\n",
    "for i in range(len(cols)):\n",
    "    cols[i] = cols[i].split('.')[-1]\n",
    "train.columns = cols\n",
    "\n",
    "# change column names in test data\n",
    "cols = test.columns[1:].to_list()\n",
    "test = test[cols]\n",
    "for i in range(len(cols)):\n",
    "    cols[i] = cols[i].split('.')[-1]\n",
    "test.columns = cols\n",
    "\n",
    "for col in train.columns:\n",
    "    train.loc[train[col]== -99.9, col] = np.nan\n",
    "    train.loc[train[col]==-99, col] = np.nan\n",
    "for col in test.columns:\n",
    "    test.loc[test[col]== -99.9, col] = np.nan\n",
    "    test.loc[test[col]==-99, col] = np.nan\n",
    "\n",
    "for i in range(len(train['year'].unique())):\n",
    "    year = train['year'].unique()[i]\n",
    "    train.loc[train['year'] == year, 'year'] = 2000 + i\n",
    "test['year'] = 2003\n",
    "\n",
    "# fill missing value\n",
    "interpolate_columns = ['ws10_deg', 'ws10_ms', 'ta', 'hm', 'sun10', 'ts']\n",
    "for loc in train['stn_id'].unique():\n",
    "    for col in interpolate_columns:\n",
    "        train.loc[train['stn_id'] == loc, col] = train.loc[train['stn_id'] == loc, col].interpolate(method = 'linear')\n",
    "    train.loc[train['stn_id'] == loc, interpolate_columns] = train.loc[train['stn_id'] == loc, interpolate_columns].fillna(method = 'ffill')\n",
    "    train.loc[train['stn_id'] == loc, interpolate_columns] = train.loc[train['stn_id'] == loc, interpolate_columns].fillna(method = 'bfill')\n",
    "train['re'] = train['re'].fillna(0)\n",
    "\n",
    "for loc in test['stn_id'].unique():\n",
    "    for col in interpolate_columns:\n",
    "        test.loc[test['stn_id'] == loc, col] = test.loc[test['stn_id'] == loc, col].interpolate(method = 'linear')\n",
    "    test.loc[test['stn_id'] == loc, interpolate_columns] = test.loc[test['stn_id'] == loc, interpolate_columns].fillna(method = 'ffill')\n",
    "    test.loc[test['stn_id'] == loc, interpolate_columns] = test.loc[test['stn_id'] == loc, interpolate_columns].fillna(method = 'bfill')\n",
    "test['re'] = test['re'].fillna(0)\n",
    "\n",
    "# make derived variables\n",
    "train['dew'] = (train.hm/100)**(1/8)*(112+0.9+train.ta)+(0.1*train.ta)-112\n",
    "test['dew'] = (test.hm/100)**(1/8)*(112+0.9+test.ta)+(0.1*test.ta)-112\n",
    "\n",
    "train['taVSdew'] = train['ta'] - train['dew']\n",
    "test['taVSdew'] = test['ta'] - test['dew']\n",
    "\n",
    "train['tsVSta'] = train['ts'] - train['ta']\n",
    "test['tsVSta'] = test['ts'] - test['ta']\n",
    "\n",
    "train = train.dropna(subset = ['class', 'vis1'])\n",
    "train = train.fillna(0)\n",
    "test = test.fillna(0)\n",
    "\n",
    "for stn in train['stn_id'].unique():\n",
    "    stn_id = stn[0]\n",
    "    train.loc[train['stn_id']==stn, 'stn_id'] = stn_id\n",
    "    \n",
    "for stn in test['stn_id'].unique():\n",
    "    stn_id = stn[0]\n",
    "    test.loc[test['stn_id']==stn, 'stn_id'] = stn_id\n",
    "\n",
    "train.loc[train[\"stn_id\"] == \"A\", \"stn_id\"] = 0\n",
    "train.loc[train[\"stn_id\"] == \"B\", \"stn_id\"] = 1\n",
    "train.loc[train[\"stn_id\"] == \"C\", \"stn_id\"] = 2\n",
    "train.loc[train[\"stn_id\"] == \"D\", \"stn_id\"] = 3\n",
    "train.loc[train[\"stn_id\"] == \"E\", \"stn_id\"] = 4\n",
    "train[\"stn_id\"] = train[\"stn_id\"].astype(int)\n",
    "\n",
    "test.loc[test[\"stn_id\"] == \"A\", \"stn_id\"] = 0\n",
    "test.loc[test[\"stn_id\"] == \"B\", \"stn_id\"] = 1\n",
    "test.loc[test[\"stn_id\"] == \"C\", \"stn_id\"] = 2\n",
    "test.loc[test[\"stn_id\"] == \"D\", \"stn_id\"] = 3\n",
    "test.loc[test[\"stn_id\"] == \"E\", \"stn_id\"] = 4\n",
    "test[\"stn_id\"] = test[\"stn_id\"].astype(int)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Method\n",
    "### (1) Oversampling for classifying 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1.0    3101809\n",
       "0.0    1550904\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_for_find_4 = train.copy()\n",
    "test_for_find_4 = test.copy()\n",
    "\n",
    "train_for_find_4.loc[train_for_find_4[\"class\"]!=4, \"class\"] = 0\n",
    "train_for_find_4.loc[train_for_find_4[\"class\"]==4, \"class\"] = 1\n",
    "\n",
    "X = train_for_find_4.drop([\"class\", \"vis1\"], axis=1)\n",
    "y = train_for_find_4[\"class\"]\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Classification 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    260646\n",
       "0      2154\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(random_state=42)\n",
    "model.fit(X_res, y_res)\n",
    "\n",
    "pred_for_val = model.predict(train.drop([\"vis1\", \"class\"], axis=1))\n",
    "pred_for_val_df = pd.DataFrame(pred_for_val)\n",
    "\n",
    "pred_for_4 = model.predict(test.drop(\"class\", axis=1))\n",
    "test[\"class\"] = pred_for_4\n",
    "test[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Making Derived Variable with \"re\" for classifying 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test[\"class\"]==1, \"class\"] = 4\n",
    "_idx = test.loc[test[\"class\"] != 4].index\n",
    "\n",
    "temp_train = pd.read_csv('data/fog_train.csv', encoding = 'euc-kr')\n",
    "temp_test = pd.read_csv('data/fog_test.csv', encoding = 'euc-kr')\n",
    "# change column names it train data\n",
    "cols = temp_train.columns[1:].to_list()\n",
    "temp_train = temp_train[cols]\n",
    "for i in range(len(cols)):\n",
    "    cols[i] = cols[i].split('.')[-1]\n",
    "temp_train.columns = cols\n",
    "# change column names in test data\n",
    "cols = temp_test.columns[1:].to_list()\n",
    "temp_test = temp_test[cols]\n",
    "for i in range(len(cols)):\n",
    "    cols[i] = cols[i].split('.')[-1]\n",
    "temp_test.columns = cols\n",
    "\n",
    "for i in range(len(train['year'].unique())):\n",
    "    year = temp_train['year'].unique()[i]\n",
    "    temp_train.loc[temp_train['year'] == year, 'year'] = 2000 + i\n",
    "temp_test['year'] = 2003\n",
    "\n",
    "temp_train['time'] = temp_train['year'].astype(int).astype(str) + '-' + temp_train['month'].astype(int).astype(str) + '-' + temp_train['day'].astype(int).astype(str) + ' ' + temp_train['time'].astype(int).astype(str) + ':' + temp_train['minute'].astype(int).astype(str)\n",
    "temp_train['datetime'] = pd.to_datetime(temp_train['time'])\n",
    "\n",
    "temp_test['time'] = temp_test['year'].astype(int).astype(str) + '-' + temp_test['month'].astype(int).astype(str) + '-' + temp_test['day'].astype(int).astype(str) + ' ' + temp_test['time'].astype(int).astype(str) + ':' + temp_test['minute'].astype(int).astype(str)\n",
    "temp_test['datetime'] = pd.to_datetime(temp_test['time'])\n",
    "\n",
    "temp_cols = ['datetime', 'stn_id', 're']\n",
    "temp_train = temp_train[temp_cols]\n",
    "temp_test = temp_test[temp_cols]\n",
    "\n",
    "temp_train['re'] = temp_train['re'].fillna(0)\n",
    "temp_test['re'] = temp_test['re'].fillna(0)\n",
    "\n",
    "lag_hours = [3, 18, 21, 24]\n",
    "for lag in lag_hours:\n",
    "    temp_train[f're_{lag}'] = 0\n",
    "    temp_test[f're_{lag}'] = 0\n",
    "\n",
    "for stn in temp_train['stn_id'].unique():\n",
    "    temp = temp_train.loc[temp_train['stn_id']==stn, 're'].tolist()\n",
    "    for lag in lag_hours:\n",
    "        temp_lag = []\n",
    "        for i in range(len(temp)):\n",
    "            if i - lag*6 < 0:\n",
    "                temp_lag.append(max(temp[:i+1]))\n",
    "            else:\n",
    "                temp_lag.append(max(temp[i-lag:i+1]))\n",
    "        temp_train.loc[temp_train['stn_id']==stn, f're_{lag}'] = temp_lag\n",
    "\n",
    "for stn in temp_test['stn_id'].unique():\n",
    "    temp = temp_test.loc[temp_test['stn_id']==stn, 're'].tolist()\n",
    "    for lag in lag_hours:\n",
    "        temp_lag = []\n",
    "        for i in range(len(temp)):\n",
    "            if i - lag*6 < 0:\n",
    "                temp_lag.append(max(temp[:i+1]))\n",
    "            else:\n",
    "                temp_lag.append(max(temp[i-lag:i+1]))\n",
    "        temp_test.loc[temp_test['stn_id']==stn, f're_{lag}'] = temp_lag\n",
    "\n",
    "_train = train.copy()\n",
    "\n",
    "for lag in lag_hours:\n",
    "    _train[f're_{lag}'] = temp_train.loc[_train.index, f're_{lag}']\n",
    "    test[f're_{lag}'] = temp_test.loc[test.index, f're_{lag}']\n",
    "__train = _train.copy()\n",
    "\n",
    "_train = _train.loc[_train[\"class\"]!=4]\n",
    "_train.loc[train[\"class\"] == 1, \"class\"] =0\n",
    "_train.loc[train[\"class\"] == 2, \"class\"] =1\n",
    "_train.loc[train[\"class\"] == 3, \"class\"] =2\n",
    "_train = _train.reset_index(drop=True)\n",
    "\n",
    "X = _train.drop([\"class\", \"vis1\"], axis=1)\n",
    "y = _train[\"class\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Classification 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "4    260646\n",
       "2      1261\n",
       "3       649\n",
       "1       244\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(random_state=42)\n",
    "model.fit(X,y)\n",
    "\n",
    "val_idx = pred_for_val_df.loc[pred_for_val_df[0] == 0].index\n",
    "pred_for_val_df += 3\n",
    "valid_idx = train.index.intersection(val_idx)\n",
    "val_train = __train.loc[valid_idx, :]\n",
    "pred_for_val_multi = model.predict(val_train.drop([\"vis1\", \"class\"], axis=1))\n",
    "pred_for_val_multi += 1\n",
    "pred_for_val_df.loc[valid_idx, 0] = pred_for_val_multi\n",
    "\n",
    "pred = model.predict(test.loc[_idx,:].drop(\"class\", axis=1))\n",
    "pred += 1\n",
    "test.loc[_idx,\"class\"] = pred\n",
    "test[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) CSI Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSI: 0.09631072162717733\n"
     ]
    }
   ],
   "source": [
    "CSI(pred_for_val_df[0], train[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Compare target data ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "4.0    98.974646\n",
      "3.0     0.388648\n",
      "2.0     0.385712\n",
      "1.0     0.250994\n",
      "Name: count, dtype: float64\n",
      "\n",
      "\n",
      "class\n",
      "4    99.180365\n",
      "2     0.479833\n",
      "3     0.246956\n",
      "1     0.092846\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train[\"class\"].value_counts() / len(train) * 100)\n",
    "print()\n",
    "print()\n",
    "print(test[\"class\"].value_counts() / len(test) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make file for submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/fog_test.csv')\n",
    "sub[\"fog_test.class\"] = test[\"class\"]\n",
    "sub.to_csv(\"240247.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
